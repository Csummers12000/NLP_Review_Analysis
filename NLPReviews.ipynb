{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd02db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Importing Necessary Libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "import pyLDAvis.gensim_models"
   ]
  },
  {
   "source": [
    "# Loading, Cleaning, and Tokenizing the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            Restaurant                                             Review  \\\n",
       "0      Beyond Flavours  The ambience was good, food was quite good . h...   \n",
       "1      Beyond Flavours  Ambience is too good for a pleasant evening. S...   \n",
       "2      Beyond Flavours  A must try.. great food great ambience. Thnx f...   \n",
       "3      Beyond Flavours  Soumen das and Arun was a great guy. Only beca...   \n",
       "4      Beyond Flavours  Food is good.we ordered Kodi drumsticks and ba...   \n",
       "...                ...                                                ...   \n",
       "9956  Chinese Pavilion  Madhumathi Mahajan Well to start with nice cou...   \n",
       "9957  Chinese Pavilion  This place has never disappointed us.. The foo...   \n",
       "9958  Chinese Pavilion  Bad rating is mainly because of \"Chicken Bone ...   \n",
       "9959  Chinese Pavilion  I personally love and prefer Chinese Food. Had...   \n",
       "9960  Chinese Pavilion  Checked in here to try some delicious chinese ...   \n",
       "\n",
       "      No_Of_Raters           Time   Cost  American  Asian  French  Indian  \\\n",
       "0                5  5/25/19 15:54    800         0      1       0       0   \n",
       "1                5  5/25/19 14:20    800         0      1       0       0   \n",
       "2                5  5/24/19 22:54    800         0      1       0       0   \n",
       "3                5  5/24/19 22:11    800         0      1       0       0   \n",
       "4                5  5/24/19 21:37    800         0      1       0       0   \n",
       "...            ...            ...    ...       ...    ...     ...     ...   \n",
       "9956             3    6/5/16 0:08  1,000         0      1       0       0   \n",
       "9957             5   6/4/16 22:01  1,000         0      0       0       1   \n",
       "9958             2   6/3/16 10:37  1,000         0      0       0       1   \n",
       "9959             4  5/31/16 17:22  1,000         0      1       0       0   \n",
       "9960             4  5/31/16 16:41  1,000         0      1       0       0   \n",
       "\n",
       "      Mediterranean  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "...             ...  \n",
       "9956              0  \n",
       "9957              0  \n",
       "9958              0  \n",
       "9959              0  \n",
       "9960              0  \n",
       "\n",
       "[9954 rows x 10 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Restaurant</th>\n      <th>Review</th>\n      <th>No_Of_Raters</th>\n      <th>Time</th>\n      <th>Cost</th>\n      <th>American</th>\n      <th>Asian</th>\n      <th>French</th>\n      <th>Indian</th>\n      <th>Mediterranean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Beyond Flavours</td>\n      <td>The ambience was good, food was quite good . h...</td>\n      <td>5</td>\n      <td>5/25/19 15:54</td>\n      <td>800</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Beyond Flavours</td>\n      <td>Ambience is too good for a pleasant evening. S...</td>\n      <td>5</td>\n      <td>5/25/19 14:20</td>\n      <td>800</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Beyond Flavours</td>\n      <td>A must try.. great food great ambience. Thnx f...</td>\n      <td>5</td>\n      <td>5/24/19 22:54</td>\n      <td>800</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Beyond Flavours</td>\n      <td>Soumen das and Arun was a great guy. Only beca...</td>\n      <td>5</td>\n      <td>5/24/19 22:11</td>\n      <td>800</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Beyond Flavours</td>\n      <td>Food is good.we ordered Kodi drumsticks and ba...</td>\n      <td>5</td>\n      <td>5/24/19 21:37</td>\n      <td>800</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9956</th>\n      <td>Chinese Pavilion</td>\n      <td>Madhumathi Mahajan Well to start with nice cou...</td>\n      <td>3</td>\n      <td>6/5/16 0:08</td>\n      <td>1,000</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9957</th>\n      <td>Chinese Pavilion</td>\n      <td>This place has never disappointed us.. The foo...</td>\n      <td>5</td>\n      <td>6/4/16 22:01</td>\n      <td>1,000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9958</th>\n      <td>Chinese Pavilion</td>\n      <td>Bad rating is mainly because of \"Chicken Bone ...</td>\n      <td>2</td>\n      <td>6/3/16 10:37</td>\n      <td>1,000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9959</th>\n      <td>Chinese Pavilion</td>\n      <td>I personally love and prefer Chinese Food. Had...</td>\n      <td>4</td>\n      <td>5/31/16 17:22</td>\n      <td>1,000</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9960</th>\n      <td>Chinese Pavilion</td>\n      <td>Checked in here to try some delicious chinese ...</td>\n      <td>4</td>\n      <td>5/31/16 16:41</td>\n      <td>1,000</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>9954 rows Ã— 10 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "df = pd.read_csv('RestaurantReviews.csv')\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The ambience was good, food was quite good . had Saturday lunch , which was cost effective . Good place for a sate brunch. One can also chill with friends and or parents. Waiter Soumen Das was really courteous and helpful.\n"
     ]
    }
   ],
   "source": [
    "reviews = df['Review'].tolist()\n",
    "reviews = [re.sub('\\s+', ' ', thing) for thing in reviews]\n",
    "reviews = [re.sub(\"\\'\", \"\", thing) for thing in reviews]\n",
    "print(reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['the', 'ambience', 'was', 'good', 'food', 'was', 'quite', 'good', 'had', 'saturday', 'lunch', 'which', 'was', 'cost', 'effective', 'good', 'place', 'for', 'sate', 'brunch', 'one', 'can', 'also', 'chill', 'with', 'friends', 'and', 'or', 'parents', 'waiter', 'soumen', 'das', 'was', 'really', 'courteous', 'and', 'helpful']\n"
     ]
    }
   ],
   "source": [
    "def tokenizer(review):\n",
    "    for word in review:\n",
    "        yield(gensim.utils.simple_preprocess(str(word), deacc=True))\n",
    "        \n",
    "tokensets = list(tokenizer(reviews))\n",
    "\n",
    "print(tokensets[0])"
   ]
  },
  {
   "source": [
    "# Creating Bigrams, Removing Stopwords, and Lemmatizing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['the', 'ambience', 'was', 'good', 'food', 'was', 'quite', 'good', 'had', 'saturday', 'lunch', 'which', 'was', 'cost_effective', 'good', 'place', 'for', 'sate', 'brunch', 'one', 'can', 'also', 'chill', 'with', 'friends', 'and', 'or', 'parents', 'waiter', 'soumen_das', 'was', 'really', 'courteous', 'and', 'helpful']\n"
     ]
    }
   ],
   "source": [
    "bigram = gensim.models.Phrases(tokensets, min_count=5, threshold=100)\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "print(bigram_mod[tokensets[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopword_remover(tokensets):\n",
    "    return [[token for token in simple_preprocess(str(tokenset)) if token not in stop_words] for tokenset in tokensets]\n",
    "\n",
    "def bigram_maker(tokensets):\n",
    "    return [bigram_mod[tokenset] for tokenset in tokensets]\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "def lemmatizer(tokensets, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    better_tokensets = []\n",
    "    for tokens in tokensets:\n",
    "        tokenset = nlp(\" \".join(tokens)) \n",
    "        better_tokensets.append([token.lemma_ for token in tokenset if token.pos_ in allowed_postags])\n",
    "    return better_tokensets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['ambience', 'good', 'food', 'quite', 'good', 'saturday', 'lunch', 'cost_effective', 'good', 'place', 'sate', 'brunch', 'also', 'chill', 'friend', 'parent', 'waiter', 'soumen_da', 'really', 'courteous', 'helpful']\n"
     ]
    }
   ],
   "source": [
    "NoStop = stopword_remover(tokensets)\n",
    "\n",
    "BiGram = bigram_maker(NoStop)\n",
    "\n",
    "best_tokensets = lemmatizer(BiGram, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(best_tokensets[0])"
   ]
  },
  {
   "source": [
    "# Using LDA to develop a topic model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 3), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1)]\n"
     ]
    }
   ],
   "source": [
    "tokenDict = corpora.Dictionary(best_tokensets)\n",
    "corpus = [tokenDict.doc2bow(tokenset) for tokenset in best_tokensets]\n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(0, '0.073*\"good\" + 0.056*\"food\" + 0.052*\"place\" + 0.027*\"service\" + 0.018*\"great\" + 0.018*\"visit\" + 0.017*\"ambience\" + 0.015*\"staff\" + 0.014*\"really\" + 0.013*\"nice\"'), (1, '0.039*\"chicken\" + 0.026*\"taste\" + 0.016*\"order\" + 0.015*\"try\" + 0.014*\"veg\" + 0.014*\"dish\" + 0.013*\"rice\" + 0.012*\"chinese\" + 0.011*\"biryani\" + 0.010*\"soup\"'), (2, '0.028*\"order\" + 0.020*\"do\" + 0.019*\"get\" + 0.018*\"restaurant\" + 0.014*\"bad\" + 0.013*\"time\" + 0.012*\"food\" + 0.012*\"even\" + 0.012*\"take\" + 0.011*\"give\"')]\n"
     ]
    }
   ],
   "source": [
    "LDA = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                      id2word=tokenDict,\n",
    "                                      num_topics=3,\n",
    "                                      random_state=100,\n",
    "                                      update_every=1,\n",
    "                                      chunksize=100,\n",
    "                                      passes=10,\n",
    "                                      alpha='auto',\n",
    "                                      per_word_topics=True)\n",
    "newLDA = LDA[corpus]\n",
    "print(LDA.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}